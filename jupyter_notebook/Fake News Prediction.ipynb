{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fake News Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "from collections import Counter\n",
    "from pprint import pprint\n",
    "from copy import copy\n",
    "from string import punctuation\n",
    "\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import gensim\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, confusion_matrix, mean_squared_error\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import MultinomialNB, GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "LabeledSentence = gensim.models.doc2vec.LabeledSentence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert stopwords and punctuation to sets for faster lookup\n",
    "stopwords_lookup = set(stopwords.words('english'))\n",
    "punctuation_lookup = set(punctuation)\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "def process_text(string_input, punctuation, stopwords, stem=True):\n",
    "    for character in string_input:\n",
    "        if character in punctuation:\n",
    "            string_input = string_input.replace(character, \"\")\n",
    "\n",
    "    processed_string = string_input.lower().split()\n",
    "\n",
    "    processed_string = ' '.join([stemmer.stem(word) for word in processed_string if word not in stopwords])\n",
    "    \n",
    "    return processed_string\n",
    "\n",
    "stopwords_lookup.add('said')\n",
    "stopwords_lookup.add('mr')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('fake_or_real_news.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop all columns apart from title and label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in df:\n",
    "    if not (key == 'title' or key == 'label'):\n",
    "        del df[key]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mold data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "label_map = {'FAKE' : 0, 'REAL' : 1}\n",
    "df['label'] = df['label'].map(label_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6335, 2)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>You Can Smell Hillary’s Fear</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Watch The Exact Moment Paul Ryan Committed Pol...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Kerry to go to Paris in gesture of sympathy</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Bernie supporters on Twitter erupt in anger ag...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The Battle of New York: Why This Primary Matters</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Tehran, USA</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Girl Horrified At What She Watches Boyfriend D...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>‘Britain’s Schindler’ Dies at 106</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Fact check: Trump and Clinton at the 'commande...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Iran reportedly makes new push for uranium con...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  label\n",
       "0                       You Can Smell Hillary’s Fear      0\n",
       "1  Watch The Exact Moment Paul Ryan Committed Pol...      0\n",
       "2        Kerry to go to Paris in gesture of sympathy      1\n",
       "3  Bernie supporters on Twitter erupt in anger ag...      0\n",
       "4   The Battle of New York: Why This Primary Matters      1\n",
       "5                                        Tehran, USA      0\n",
       "6  Girl Horrified At What She Watches Boyfriend D...      0\n",
       "7                  ‘Britain’s Schindler’ Dies at 106      1\n",
       "8  Fact check: Trump and Clinton at the 'commande...      1\n",
       "9  Iran reportedly makes new push for uranium con...      1"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split Data to X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df['title']    # predictor feature\n",
    "X = X.apply(lambda x: process_text(x, punctuation_lookup, stopwords_lookup)) # apply stopwords through NLTK\n",
    "X = df['title'].values # get values\n",
    "y = df['label'].values # predicted class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count and tfidf\n",
    "\n",
    "count_vectorizer = CountVectorizer(max_features=1000)\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=1000)\n",
    "\n",
    "X_count = count_vectorizer.fit_transform(X)\n",
    "X_tfidf = tfidf_vectorizer.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# doc2vec\n",
    "\n",
    "# adapted from tutorial at https://medium.com/@klintcho/doc2vec-tutorial-using-gensim-ab3ac03d3a1\n",
    "\n",
    "class LabeledSentenceIterator:\n",
    "    def __init__(self, doc_list, label_list):\n",
    "        self.doc_list = doc_list\n",
    "        \n",
    "        self.label_list = []\n",
    "        \n",
    "        self.label_list = ['Fake' if label == 0 else 'Real' for label in label_list]\n",
    "        \n",
    "    def __iter__(self):\n",
    "        num_fake = 0\n",
    "        num_real = 0\n",
    "        \n",
    "        for doc, label in zip(self.doc_list, self.label_list):\n",
    "            words = doc.split()\n",
    "            \n",
    "            if label == 'Fake':\n",
    "                tag = [label + '_' + str(num_fake)]\n",
    "                num_fake += 1\n",
    "                \n",
    "            elif label == 'Real':\n",
    "                tag = [label + '_' + str(num_real)]\n",
    "                num_real += 1\n",
    "            \n",
    "            yield LabeledSentence(words = words, tags = tag)\n",
    "\n",
    "doc_iter = LabeledSentenceIterator(list(X), y)\n",
    "            \n",
    "dtov_model = gensim.models.Doc2Vec(size=300, window=10, min_count=5, workers=11,alpha=0.025, min_alpha=0.025)\n",
    "\n",
    "dtov_model.build_vocab(doc_iter)\n",
    "\n",
    "for epoch in range(10):\n",
    "    dtov_model.train(doc_iter)\n",
    "    dtov_model.alpha -= 0.002\n",
    "    dtov_model.min_alpha = dtov_model.alpha \n",
    "    dtov_model.train(doc_iter)\n",
    "    \n",
    "# save the trained doc2vec model\n",
    "# dtov_model.save('doc_to_vec.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load the model, previously trained\n",
    "# dtov_model = gensim.models.Doc2Vec.load('doc_to_vec.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_doc2vec = []\n",
    "y_doc2vec = y\n",
    "num_fake1 = 0\n",
    "num_real1 = 0\n",
    "for value in y:\n",
    "    if (value == 0):\n",
    "        X_doc2vec.append(dtov_model.docvecs['Fake_' + str(num_fake1)])\n",
    "        num_fake1 += 1\n",
    "    else:\n",
    "        X_doc2vec.append(dtov_model.docvecs['Real_' + str(num_real1)])\n",
    "        num_real1 += 1\n",
    "X_doc2vec = np.array(X_doc2vec)\n",
    "y_doc2vec = np.array(y_doc2vec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split Test and Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_test_size = 0.30\n",
    "\n",
    "X_tr_d2v, X_te_d2v, y_tr_d2v, y_te_d2v = train_test_split(X_doc2vec, y_doc2vec, test_size=split_test_size, random_state=42)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_count, y, test_size=split_test_size, random_state=42) \n",
    "                            # test_size = 0.3 is 30%, 42 is the answer to everything\n",
    "X_train_tfidf, X_test_tfidf, y_train_tfidf, y_test_tfidf = train_test_split(X_tfidf, y, test_size=split_test_size, random_state=42) \n",
    "                            # test_size = 0.3 is 30%, 42 is the answer to everything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_results(model, X_tr, X_te, y_tr, y_te):\n",
    "    model.fit(X_tr, y_tr)\n",
    "    \n",
    "    y_p = model.predict(X_te)\n",
    "    \n",
    "    print(\"Accuracy Score: {}\".format(accuracy_score(y_p, y_te)))\n",
    "    \n",
    "    print(\"\\nPrecision/Recall/F-Score/Support: \\n\")\n",
    "    pprint(precision_recall_fscore_support(y_te, y_p))\n",
    "    \n",
    "    print(\"\\nConfusion Matrix:\\n\")\n",
    "    pprint(confusion_matrix(y_te, y_p))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Baseline model is a multinomial Naive Bayes classifier using Count vectorization for feature extraction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score: 0.7890583903208838\n",
      "\n",
      "Precision/Recall/F-Score/Support: \n",
      "\n",
      "(array([ 0.78899083,  0.78913043]),\n",
      " array([ 0.79958678,  0.77813505]),\n",
      " array([ 0.79425346,  0.78359417]),\n",
      " array([968, 933]))\n",
      "\n",
      "Confusion Matrix:\n",
      "\n",
      "array([[774, 194],\n",
      "       [207, 726]])\n"
     ]
    }
   ],
   "source": [
    "mnbModel = MultinomialNB()\n",
    "\n",
    "show_results(mnbModel, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Baseline Model using TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score: 0.7859021567596002\n",
      "\n",
      "Precision/Recall/F-Score/Support: \n",
      "\n",
      "(array([ 0.78593272,  0.78586957]),\n",
      " array([ 0.7964876 ,  0.77491961]),\n",
      " array([ 0.79117496,  0.78035618]),\n",
      " array([968, 933]))\n",
      "\n",
      "Confusion Matrix:\n",
      "\n",
      "array([[771, 197],\n",
      "       [210, 723]])\n"
     ]
    }
   ],
   "source": [
    "show_results(mnbModel, X_train_tfidf, X_test_tfidf, y_train_tfidf, y_test_tfidf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Baseline Model using Doc2Vec Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show_results(mnbModel, X_tr_d2v, X_te_d2v, y_tr_d2v, y_te_d2v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Penalized Logistic Regression with CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score: 0.8043135192004208\n",
      "\n",
      "Precision/Recall/F-Score/Support: \n",
      "\n",
      "(array([ 0.80595483,  0.802589  ]),\n",
      " array([ 0.81095041,  0.79742765]),\n",
      " array([ 0.8084449,  0.8      ]),\n",
      " array([968, 933]))\n",
      "\n",
      "Confusion Matrix:\n",
      "\n",
      "array([[785, 183],\n",
      "       [189, 744]])\n"
     ]
    }
   ],
   "source": [
    "logisticModel = LogisticRegression()\n",
    "\n",
    "show_results(logisticModel, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Penalized Logistic Regression with TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score: 0.8001052077853761\n",
      "\n",
      "Precision/Recall/F-Score/Support: \n",
      "\n",
      "(array([ 0.79458918,  0.80620155]),\n",
      " array([ 0.81921488,  0.78027867]),\n",
      " array([ 0.80671414,  0.79302832]),\n",
      " array([968, 933]))\n",
      "\n",
      "Confusion Matrix:\n",
      "\n",
      "array([[793, 175],\n",
      "       [205, 728]])\n"
     ]
    }
   ],
   "source": [
    "logisticModel = LogisticRegression()\n",
    "\n",
    "show_results(logisticModel, X_train_tfidf, X_test_tfidf, y_train_tfidf, y_test_tfidf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Penalized Logistic Regression with Doc2Vec Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score: 0.7622304050499737\n",
      "\n",
      "Precision/Recall/F-Score/Support: \n",
      "\n",
      "(array([ 0.76875   ,  0.75557917]),\n",
      " array([ 0.76239669,  0.76205788]),\n",
      " array([ 0.76556017,  0.7588047 ]),\n",
      " array([968, 933]))\n",
      "\n",
      "Confusion Matrix:\n",
      "\n",
      "array([[738, 230],\n",
      "       [222, 711]])\n"
     ]
    }
   ],
   "source": [
    "logisticModel = LogisticRegression()\n",
    "\n",
    "show_results(logisticModel, X_tr_d2v, X_te_d2v, y_tr_d2v, y_te_d2v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest with CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score: 0.7901104681746449\n",
      "\n",
      "Precision/Recall/F-Score/Support: \n",
      "\n",
      "(array([ 0.79543094,  0.78464819]),\n",
      " array([ 0.79132231,  0.78885316]),\n",
      " array([ 0.79337131,  0.78674506]),\n",
      " array([968, 933]))\n",
      "\n",
      "Confusion Matrix:\n",
      "\n",
      "array([[766, 202],\n",
      "       [197, 736]])\n"
     ]
    }
   ],
   "source": [
    "forestModel = RandomForestClassifier(n_estimators = 100)\n",
    "\n",
    "show_results(forestModel, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest with TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score: 0.7837980010520779\n",
      "\n",
      "Precision/Recall/F-Score/Support: \n",
      "\n",
      "(array([ 0.7696031 ,  0.80069124]),\n",
      " array([ 0.82128099,  0.7449089 ]),\n",
      " array([ 0.7946027 ,  0.77179345]),\n",
      " array([968, 933]))\n",
      "\n",
      "Confusion Matrix:\n",
      "\n",
      "array([[795, 173],\n",
      "       [238, 695]])\n"
     ]
    }
   ],
   "source": [
    "forestModel = RandomForestClassifier(n_estimators = 100)\n",
    "\n",
    "show_results(forestModel, X_train_tfidf, X_test_tfidf, y_train_tfidf, y_test_tfidf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest with Doc2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score: 0.769594950026302\n",
      "\n",
      "Precision/Recall/F-Score/Support: \n",
      "\n",
      "(array([ 0.76606426,  0.77348066]),\n",
      " array([ 0.78822314,  0.75026795]),\n",
      " array([ 0.77698574,  0.7616975 ]),\n",
      " array([968, 933]))\n",
      "\n",
      "Confusion Matrix:\n",
      "\n",
      "array([[763, 205],\n",
      "       [233, 700]])\n"
     ]
    }
   ],
   "source": [
    "forestModel = RandomForestClassifier(n_estimators = 100)\n",
    "\n",
    "show_results(forestModel, X_tr_d2v, X_te_d2v, y_tr_d2v, y_te_d2v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### API Architecture for class prediction of single claim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FAKE\n",
      "59.5274171211\n"
     ]
    }
   ],
   "source": [
    "logisticModel = LogisticRegression()\n",
    "logisticModel.fit(X_train, y_train)\n",
    "label = {0:'FAKE', 1:'REAL'}\n",
    "test = ['Loretta Lynch becomes first African-American woman AG.']\n",
    "test_vector = count_vectorizer.transform(test)\n",
    "pred = logisticModel.predict(test_vector)\n",
    "print(label[pred[0]])\n",
    "proba = np.max(logisticModel.predict_proba(test_vector)) * 100\n",
    "print(proba)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
